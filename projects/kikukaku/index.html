<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><title>
         KikuKaku
        
    </title><meta content=KikuKaku property=og:title><meta content="HearWrite in Japanese. A learning tool for non-English handwriting in VR!" property=og:description><meta content="HearWrite in Japanese. A learning tool for non-English handwriting in VR!" name=description><link href=/icon/favicon.png rel=icon type=image/png><link href=https://fenreese.github.io/fonts.css rel=stylesheet><script>MathJax={tex:{inlineMath:[[`\$`,`\$`],[`\\\\(`,`\\\\)`]]}}</script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link href=https://fenreese.github.io/atom.xml rel=alternate title=renys.dev type=application/atom+xml><link href=https://fenreese.github.io/theme/light.css rel=stylesheet><link href=https://fenreese.github.io/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://fenreese.github.io/js/themetoggle.js></script><script>setTheme(getSavedTheme())</script><link href=https://fenreese.github.io/main.css media=screen rel=stylesheet><link href=https://fenreese.github.io/colours.css rel=stylesheet><body><div class=content><header><div class=main><a href=https://fenreese.github.io>renys.dev</a><div class=socials><a class=social href=https://linkedin.com/in/reesedominguez rel=me> <img alt=linkedin src=https://fenreese.github.io/social_icons/linkedin.svg> </a><a class=social href=https://github.com/fenreese/ rel=me> <img alt=github src=https://fenreese.github.io/social_icons/github.svg> </a></div></div><nav><a href=https://fenreese.github.io/about style=margin-left:.5em>about</a><a href=https://fenreese.github.io/posts style=margin-left:.5em>writing</a><a href=https://fenreese.github.io/tags style=margin-left:.5em>tags</a><a href=https://fenreese.github.io/projects style=margin-left:.5em>projects</a> |<a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://fenreese.github.io/feather/sun.svg style=filter:invert()> <img alt=Dark id=moon-icon src=https://fenreese.github.io/feather/moon.svg> </a><script>updateItemToggleTheme()</script></nav></header><main><article><div class=title><div class=page-header>KikuKaku<span class=primary-color style=font-size:1.6em>.</span></div><div class=meta></div></div><section class=body><p><img alt='A screenshot from an Oculus HMD. A pop-up menu near the top of an image shows the word "bentou" in Japanese, along with buttons to cancel, change the size of a letter, undo the latest letter, and submit the word. Below it is a whiteboard for the user to write a letter on. There is a left hand holding a pen in front of the whiteboard.' src=/projects/kikukaku.jpg> <em>there is a べんとう behind this big writing surface</em><p>My fourth year honors thesis. Written as 聞く書く in Japanese, it is a virtual reality learning application meant to help learners refine their listening and handwriting skills in non-English languages. Made with Unity and the OpenXR toolkit, you are to "own" as much vocabulary objects as possible by correctly writing the word you hear. This was my first solo VR project (the rest were group hackathon projects), so I was responsible for doing <em>everything</em>, from the game design to the API behind it.<p>I'm particularly proud of the implementation of the writing board/canvas in VR - I took inspiration from the whiteboards in Half-Life: Alyx and got help from <a href=https://fenreese.github.io/projects/kikukaku/80.lv/articles/recreating-the-drawing-mechanic-from-half-life-alyx-in-unity>this article</a> with implementing it. Because the process was a bit hacky, though, there were a few problems with needing to clear the canvas after each successful character write. I ended up quickly patching by destroying the object, waiting a bit, and then spawning the object again.<p>The character recognition was a simple multilayer perceptron machine learning model, which is pretty much converting an image into pixels and numbers, then having the computer learn what combinations of pixels are associated with which Japanese hiragana character in order to predict them. The model is 99% accurate in its predictions, which shocked even me. It was implemented in Tensorflow with Keras, and deployed as a Flask API.<p>Here is <a href=https://youtu.be/ENDjb0ghphA>a video</a> of some gameplay. Also see: the <a href=https://github.com/vialab/JPHandwriting>source code</a>.</section></article></main></div>